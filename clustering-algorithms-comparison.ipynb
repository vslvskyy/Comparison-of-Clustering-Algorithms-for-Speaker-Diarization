{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing"
      ],
      "metadata": {
        "id": "AkAFo1_NOVfl"
      },
      "id": "AkAFo1_NOVfl"
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "ROOT = 'drive/MyDrive/diarization' # путь до папки diarization"
      ],
      "metadata": {
        "id": "gU8DiYwriSsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c01adee-cd3e-404e-dace-8a852b056d61"
      },
      "id": "gU8DiYwriSsf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import glob2\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "B8STpszmAFfh"
      },
      "id": "B8STpszmAFfh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEgqNsMN_pF9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "xEgqNsMN_pF9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXIn2vgn_pF-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio"
      ],
      "id": "qXIn2vgn_pF-"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip"
      ],
      "metadata": {
        "id": "19Arqub2GWWS"
      },
      "id": "19Arqub2GWWS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZPuUBb5_pF-"
      },
      "outputs": [],
      "source": [
        "from pyannote.core import Annotation, Timeline, Segment, SlidingWindow\n",
        "from pyannote.database.util import load_rttm\n",
        "from pyannote.audio import Model\n",
        "from pyannote.audio.pipelines import VoiceActivityDetection, OverlappedSpeechDetection\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate, JaccardErrorRate"
      ],
      "id": "oZPuUBb5_pF-"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!pip install speechbrain"
      ],
      "metadata": {
        "id": "thdK0Bo8M3xi"
      },
      "id": "thdK0Bo8M3xi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KIJqXb3_pF-"
      },
      "outputs": [],
      "source": [
        "from drive.MyDrive.diarization.data_io import load_audio\n",
        "from drive.MyDrive.diarization.backend import transform_embeddings, prepare_plda\n",
        "from drive.MyDrive.diarization.embedder.brno.wrapper import prepare_model_brno\n",
        "from drive.MyDrive.diarization.embedder.clova.wrapper import prepare_model_clova\n",
        "from drive.MyDrive.diarization.embedder.speechbrain.wrapper import prepare_model_speechbrain\n",
        "from drive.MyDrive.diarization.segmentation import split_segments, split_overlap_part\n",
        "from drive.MyDrive.diarization.features import extract_embeddings\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from drive.MyDrive.diarization.clustering import VB_diarization, VB_diarization_UP"
      ],
      "id": "1KIJqXb3_pF-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice activity and overlapped speech detection"
      ],
      "metadata": {
        "id": "01Uq4cLXEJ0t"
      },
      "id": "01Uq4cLXEJ0t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "cyB8YMlbuN7X"
      },
      "id": "cyB8YMlbuN7X"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_annotations(data_root, dataset_name, data_type, HYPER_PARAMETERS):\n",
        "    if dataset_name == 'ami':\n",
        "        uris = []\n",
        "\n",
        "        for wav in glob2.glob(os.path.join(data_root, '*.rttm')):\n",
        "            uris.append(os.path.splitext(os.path.basename(wav))[0])\n",
        "        uri2path = {uri: f\"amicorpus/{uri}/audio/{uri}.Mix-Headset.wav\" for uri in uris}\n",
        "    else:\n",
        "        if dataset_name == 'aishell':\n",
        "            extention = 'wav/*.flac'\n",
        "        elif dataset_name == 'voxconverse':\n",
        "            extention = f'voxconverse_{data_type}_wav/*.wav' # data_type \\in {test, dev}\n",
        "            if data_type == 'dev':\n",
        "                extention = 'audio/*.wav'\n",
        "        else:\n",
        "            print(\"unknown dataset_name\")\n",
        "            return\n",
        "            \n",
        "        wav_list = glob2.glob(os.path.join(data_root, extention))\n",
        "        uri2path = {os.path.splitext(os.path.basename(wav))[0]: wav for wav in wav_list}\n",
        "    uri2ann_ref = {}\n",
        "\n",
        "\n",
        "    if dataset_name == 'aishell':\n",
        "        extention = 'TextGrid/'\n",
        "    elif dataset_name == 'voxconverse':\n",
        "        extention = data_type+'/' # data_type \\in {test, dev}\n",
        "        data_root = 'voxconverse'\n",
        "    elif dataset_name == 'ami':\n",
        "        extention = \"\"\n",
        "\n",
        "    for uri in uri2path:\n",
        "        uri2ann_ref.update(load_rttm(os.path.join(data_root, f'{extention}{uri}.rttm')))\n",
        "\n",
        "    uri2vad = {}\n",
        "    uri2osd = {}\n",
        "    for uri, wav_path in uri2path.items():\n",
        "        vad = uri2ann_ref[uri].get_timeline().support()\n",
        "        osd = vad.get_overlap()\n",
        "\n",
        "        uri2vad[uri] = vad\n",
        "        uri2osd[uri] = osd\n",
        "      \n",
        "    np.save(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2vad.npy', uri2vad)\n",
        "    np.save(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2osd.npy', uri2osd)\n",
        "    np.save(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2path.npy', uri2path)\n",
        "    np.save(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2ann_ref.npy', uri2ann_ref)\n",
        "\n",
        "    return vad_model, osd_model"
      ],
      "metadata": {
        "id": "JLzPM80Yoe8i"
      },
      "id": "JLzPM80Yoe8i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Aishell4 Annotations\n",
        "\n"
      ],
      "metadata": {
        "id": "aCX5zZkY0Hwa"
      },
      "id": "aCX5zZkY0Hwa"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/test.tar.gz # AISHELL\n",
        "!tar xfvz test.tar.gz # for AISHELL\n",
        "!rm -r test.tar.gz\n",
        "data_root_aishell4_test = 'test'\n",
        "\n",
        "get_annotations(data_root_aishell4_test, 'aishell', 'test', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r test"
      ],
      "metadata": {
        "id": "RxlnhtihpRwt"
      },
      "id": "RxlnhtihpRwt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_M.tar.gz # AISHELL\n",
        "!tar xfvz train_M.tar.gz # for AISHELL\n",
        "!rm -r train_M.tar.gz\n",
        "data_root_aishell4_train_M = 'train_M'\n",
        "\n",
        "get_annotations(data_root_aishell4_train_M, 'aishell', 'train_M', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r train_M"
      ],
      "metadata": {
        "id": "nTF8I0Y-zOze"
      },
      "id": "nTF8I0Y-zOze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_S.tar.gz # AISHELL\n",
        "!tar xfvz train_S.tar.gz # for AISHELL\n",
        "!rm -r train_S.tar.gz\n",
        "data_root_aishell4_train_S = 'train_S'\n",
        "\n",
        "get_annotations(data_root_aishell4_train_S, 'aishell', 'train_S', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r train_S"
      ],
      "metadata": {
        "id": "0EP3BtfLSM2N"
      },
      "id": "0EP3BtfLSM2N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_L.tar.gz # AISHELL\n",
        "!tar xfvz train_L.tar.gz # for AISHELL\n",
        "!rm -r train_L.tar.gz\n",
        "data_root_aishell4_train_L = 'train_L'\n",
        "\n",
        "get_annotations(data_root_aishell4_train_L, 'aishell', 'train_L', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r train_L"
      ],
      "metadata": {
        "id": "gitSZErx2wNy"
      },
      "id": "gitSZErx2wNy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Voxconverse Annotations"
      ],
      "metadata": {
        "id": "CQnd3hPy0OIL"
      },
      "id": "CQnd3hPy0OIL"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_test_wav.zip # VOXCONVERSE\n",
        "!unzip voxconverse_test_wav.zip -d voxconverse_test_wav # for VOXCONVERSE\n",
        "!rm -r voxconverse_test_wav.zip\n",
        "!git clone https://github.com/joonson/voxconverse \n",
        "data_root_voxconverse_test = 'voxconverse_test_wav'\n",
        "\n",
        "get_annotations(data_root_voxconverse_test, 'voxconverse', 'test', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r voxconverse_test_wav"
      ],
      "metadata": {
        "id": "MHbmF6A3za_V"
      },
      "id": "MHbmF6A3za_V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_dev_wav.zip # VOXCONVERSE\n",
        "!unzip voxconverse_dev_wav.zip -d voxconverse_dev_wav # for VOXCONVERSE\n",
        "!rm -r voxconverse_dev_wav.zip\n",
        "!git clone https://github.com/joonson/voxconverse \n",
        "data_root_voxconverse_test = 'voxconverse_dev_wav'\n",
        "\n",
        "get_annotations(data_root_voxconverse_test, 'voxconverse', 'dev', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r voxconverse_dev_wav\n",
        "!rm -r voxconverse "
      ],
      "metadata": {
        "id": "uf__8Wcp4NIM"
      },
      "id": "uf__8Wcp4NIM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Ami Annotations"
      ],
      "metadata": {
        "id": "KAAg0bap0Tb9"
      },
      "id": "KAAg0bap0Tb9"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/pyannote/AMI-diarization-setup/blob/main/pyannote/download_ami.sh # AMI\n",
        "!git clone https://github.com/pyannote/AMI-diarization-setup ami # for AMI\n",
        "!sh ami/pyannote/download_ami.sh\n",
        "\n",
        "data_root_ami_test = 'ami/only_words/rttms/test'\n",
        "get_annotations(data_root_ami_test, 'ami', 'test', HYPER_PARAMETERS)\n",
        "\n",
        "data_root_ami_dev = 'ami/only_words/rttms/dev'\n",
        "get_annotations(data_root_ami_dev, 'ami', 'dev', HYPER_PARAMETERS)\n",
        "\n",
        "data_root_ami_train = 'ami/only_words/rttms/train'\n",
        "get_annotations(data_root_ami_train, 'ami', 'train', HYPER_PARAMETERS)\n",
        "\n",
        "!rm -r ami\n",
        "!rm -r amicorpus"
      ],
      "metadata": {
        "id": "-Dgmcnp-tHOn"
      },
      "id": "-Dgmcnp-tHOn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM9oGuF8_pGI"
      },
      "source": [
        "# Embeddings extraction"
      ],
      "id": "yM9oGuF8_pGI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraction functions"
      ],
      "metadata": {
        "id": "8thWKqqwW_3P"
      },
      "id": "8thWKqqwW_3P"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(embedder_name, dataset_name, data_type, uri2path, uri2vad, uri2osd, device='cuda:0', skip_overlap=True):\n",
        "    model_path_brno = f'{ROOT}/pretrained/brno/VBx/models/ResNet101_16kHz/nnet/raw_81.pth'\n",
        "    model_path_clova = f'{ROOT}/pretrained/clova/baseline_v2_ap.model'\n",
        "    model_path_speechbrain = f'{ROOT}/pretrained/speechbrain/embedding_model.ckpt'\n",
        "\n",
        "    if embedder_name == 'brno':\n",
        "        emb_model = prepare_model_brno(model_path_brno, device, 'onnx' if model_path_brno.endswith('onnx') else 'pytorch')\n",
        "\n",
        "    elif embedder_name == 'clova':\n",
        "        emb_model = prepare_model_clova(model_path_clova, device)\n",
        "\n",
        "    elif embedder_name == 'speechbrain':\n",
        "        emb_model = prepare_model_speechbrain(model_path_speechbrain, device)\n",
        "\n",
        "    win_size = 2.0\n",
        "    step_size = 1.0\n",
        "\n",
        "    uri2data = {}\n",
        "    it = 1\n",
        "    errors = []\n",
        "    for uri, wav_path in tqdm(uri2path.items()):\n",
        "        try:\n",
        "            vad = uri2vad[uri]\n",
        "            if skip_overlap:\n",
        "                osd = uri2osd[uri]\n",
        "                vad = vad.extrude(osd).support() # exclude segments with overlapped speech\n",
        "            \n",
        "            waveform = load_audio(wav_path)\n",
        "            \n",
        "            segments = split_segments(vad, win_size, step_size)\n",
        "            embeddings = extract_embeddings(emb_model, waveform, segments, device, batch_size=1)\n",
        "            \n",
        "            uri2data[uri] = (embeddings, segments)\n",
        "        except:\n",
        "            errors.append(it)\n",
        "        it += 1\n",
        "    print(f'{embedder_name} {dataset_name} {data_type} errors: {errors}')\n",
        "    np.save(f'{ROOT}/embeddings/skip_overlap={str(skip_overlap)}/{dataset_name}/{dataset_name}_{data_type}_uri2data_{embedder_name}.npy', uri2data)"
      ],
      "metadata": {
        "id": "K-Q_NpTHkogb"
      },
      "id": "K-Q_NpTHkogb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_embeddings(dataset_name, data_type, skip_overlap=True):\n",
        "    for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "        uri2vad = np.load(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2vad.npy', allow_pickle=True).item()\n",
        "        uri2osd = np.load(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2osd.npy', allow_pickle=True).item()\n",
        "        uri2path = np.load(f'{ROOT}/annotations/{dataset_name}/{dataset_name}_{data_type}_uri2path.npy', allow_pickle=True).item()\n",
        "\n",
        "        get_embeddings(embedder_name, dataset_name, data_type, uri2path, uri2vad, uri2osd, skip_overlap=skip_overlap)"
      ],
      "metadata": {
        "id": "vsYaRHtOyaV1"
      },
      "id": "vsYaRHtOyaV1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SKIP_OVERLAP = False # True"
      ],
      "metadata": {
        "id": "Osyb44k9Rerr"
      },
      "id": "Osyb44k9Rerr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Aishell4 Embeddings"
      ],
      "metadata": {
        "id": "FBN5GODvz38L"
      },
      "id": "FBN5GODvz38L"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/test.tar.gz # AISHELL\n",
        "!tar xfvz test.tar.gz # for AISHELL\n",
        "!rm -r test.tar.gz\n",
        "\n",
        "dataset_name, data_type = 'aishell', 'test'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)\n",
        "\n",
        "!rm -r test"
      ],
      "metadata": {
        "id": "CNXWnZtVyILs"
      },
      "id": "CNXWnZtVyILs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_M.tar.gz # AISHELL\n",
        "!tar xfvz train_M.tar.gz # for AISHELL\n",
        "!rm -r train_M.tar.gz\n",
        "\n",
        "dataset_name, data_type = 'aishell', 'train_M'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)\n",
        "\n",
        "!rm -r train_M"
      ],
      "metadata": {
        "id": "tctWT_-szVqP"
      },
      "id": "tctWT_-szVqP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_L.tar.gz # AISHELL\n",
        "!tar xfvz train_L.tar.gz # for AISHELL\n",
        "!rm -r train_L.tar.gz\n",
        "\n",
        "dataset_name, data_type = 'aishell', 'train_L'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)\n",
        "\n",
        "!rm -r train_L"
      ],
      "metadata": {
        "id": "NObY_oGvn1-C"
      },
      "id": "NObY_oGvn1-C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/111/train_S.tar.gz # AISHELL\n",
        "!tar xfvz train_S.tar.gz # for AISHELL\n",
        "!rm -r train_S.tar.gz\n",
        "\n",
        "dataset_name, data_type = 'aishell', 'train_S'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)\n",
        "\n",
        "!rm -r train_S"
      ],
      "metadata": {
        "id": "Spx1JKNOn8U8"
      },
      "id": "Spx1JKNOn8U8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаём dev set из смеси train_L, train_M, train_S\n",
        "\n",
        "for skip_overlap in [True, False]:\n",
        "    for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "        dev_uri2data, dev_uri2ann_ref = {}, {}\n",
        "        for train_type in ['train_L', 'train_M', 'train_S']:\n",
        "            train_uri2ann_ref = np.load(\n",
        "                f'{ROOT}/annotations/aishell/aishell_{train_type}_uri2ann_ref.npy', \n",
        "                allow_pickle=True\n",
        "            ).item()\n",
        "            train_uri2data = np.load(\n",
        "                f'{ROOT}/embeddings/skip_overlap={skip_overlap}/aishell/aishell_{train_type}_uri2data_{embedder_name}.npy',\n",
        "                allow_pickle=True\n",
        "            ).item()\n",
        "            for i, key in enumerate(train_uri2data.keys(), start=1):\n",
        "                try:\n",
        "                    dev_uri2data[key] = train_uri2data[key]\n",
        "                    dev_uri2ann_ref[key] = train_uri2ann_ref[key]\n",
        "                except:\n",
        "                    continue\n",
        "                if i > 6:\n",
        "                    break\n",
        "        np.save(f'{ROOT}/embeddings/skip_overlap={skip_overlap}/aishell/aishell_dev_uri2data_{embedder_name}.npy', dev_uri2data)\n",
        "        np.save(f'{ROOT}/annotations/aishell/aishell_dev_uri2ann_ref.npy', dev_uri2ann_ref)"
      ],
      "metadata": {
        "id": "kXJ4dHG-P2KY"
      },
      "id": "kXJ4dHG-P2KY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Voxconverse Embeddings"
      ],
      "metadata": {
        "id": "StnL8_a7z8P9"
      },
      "id": "StnL8_a7z8P9"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_test_wav.zip # VOXCONVERSE\n",
        "!unzip voxconverse_test_wav.zip -d voxconverse_test_wav # for VOXCONVERSE\n",
        "!rm -r voxconverse_test_wav.zip\n",
        "# !git clone https://github.com/joonson/voxconverse \n",
        "\n",
        "dataset_name, data_type = 'voxconverse', 'test'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)\n",
        "\n",
        "!rm -r voxconverse_test_wav"
      ],
      "metadata": {
        "id": "YtvGSPTuz1gR"
      },
      "id": "YtvGSPTuz1gR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_dev_wav.zip # VOXCONVERSE\n",
        "!unzip voxconverse_dev_wav.zip -d voxconverse_dev_wav # for VOXCONVERSE\n",
        "!rm -r voxconverse_dev_wav.zip\n",
        "\n",
        "dataset_name, data_type = 'voxconverse', 'dev'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP) # при skip_overlap=True не считается (speechbrain) для 70\n",
        "\n",
        "!rm -r voxconverse_dev_wav"
      ],
      "metadata": {
        "id": "X-2zvmLC1Itj"
      },
      "id": "X-2zvmLC1Itj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Ami Embeddings"
      ],
      "metadata": {
        "id": "h7p077C30bST"
      },
      "id": "h7p077C30bST"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pyannote/AMI-diarization-setup ami # for AMI\n",
        "!sh ami/pyannote/download_ami.sh"
      ],
      "metadata": {
        "id": "PC6Rql7c0dVI"
      },
      "id": "PC6Rql7c0dVI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name, data_type = 'ami', 'test'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)"
      ],
      "metadata": {
        "id": "20raAmq-12dl"
      },
      "id": "20raAmq-12dl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name, data_type = 'ami', 'dev'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)"
      ],
      "metadata": {
        "id": "rWxpzsIO2F8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90781ec1-20ee-4c72-ca73-ed961a0633c6"
      },
      "id": "rWxpzsIO2F8c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [12:17<00:00, 40.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brno ami dev errors: []\n",
            "Embedding size is 512, encoder ASP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [04:22<00:00, 14.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clova ami dev errors: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [04:56<00:00, 16.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain ami dev errors: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name, data_type = 'ami', 'train'\n",
        "\n",
        "get_all_embeddings(dataset_name, data_type, SKIP_OVERLAP)"
      ],
      "metadata": {
        "id": "RUOFfcv42MyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed684ba-598f-4162-a3f6-3395ca09e9a2"
      },
      "id": "RUOFfcv42MyU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 136/136 [1:50:14<00:00, 48.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brno ami train errors: [133]\n",
            "Embedding size is 512, encoder ASP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 136/136 [39:42<00:00, 17.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clova ami train errors: [133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 136/136 [43:45<00:00, 19.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain ami train errors: [5, 31, 37, 85, 127, 133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ami\n",
        "!rm -r amicorpus"
      ],
      "metadata": {
        "id": "m8mNbkAU2Rvz"
      },
      "id": "m8mNbkAU2Rvz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck8u-4fx_pGJ"
      },
      "source": [
        "# Clustering"
      ],
      "id": "Ck8u-4fx_pGJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLustering Functions"
      ],
      "metadata": {
        "id": "SK96kRTn0nST"
      },
      "id": "SK96kRTn0nST"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=True):\n",
        "    if metric == 'der':\n",
        "        der_metric = DiarizationErrorRate(collar=0, skip_overlap=skip_overlap)\n",
        "        for uri, ann_hyp in uri2ann_hyp.items():\n",
        "            ann_ref = uri2ann_ref[uri]\n",
        "            der_metric(ann_ref, ann_hyp)\n",
        "            \n",
        "        return der_metric.report(display=False)\n",
        "\n",
        "    elif metric == 'jer':\n",
        "        jer_metric = JaccardErrorRate(collar=0, skip_overlap=skip_overlap)\n",
        "        for uri, ann_hyp in uri2ann_hyp.items():\n",
        "            ann_ref = uri2ann_ref[uri]\n",
        "            jer_metric(ann_ref, ann_hyp)\n",
        "\n",
        "        return jer_metric.report(display=False)\n",
        "\n",
        "    else:\n",
        "        print(\"unknown metric\")\n",
        "        return"
      ],
      "metadata": {
        "id": "dtAtF4Cqap4H"
      },
      "id": "dtAtF4Cqap4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agglomarative Hierarhical CLustering"
      ],
      "metadata": {
        "id": "4YmhbT7i1RC7"
      },
      "id": "4YmhbT7i1RC7"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install optuna\n",
        "import optuna\n",
        "import traceback\n",
        "\n",
        "def get_ahc_clustering(embedder_name, uri2data, uri2ann_ref, params, skip_overlap=True, metric='der', return_hyp=False):\n",
        "    uri2ann_hyp = {}\n",
        "    for uri in uri2data:\n",
        "        embeddings_raw, segments = uri2data[uri]\n",
        "        embeddings = transform_embeddings(embeddings_raw, embedder_name)\n",
        "        embeddings[np.isnan(embeddings)] = 1\n",
        "        embeddings[np.isinf(embeddings)] = 100\n",
        "        try:\n",
        "            ahc = AgglomerativeClustering(\n",
        "                      n_clusters=None,\n",
        "                      affinity='cosine',\n",
        "                      **params\n",
        "                )  \n",
        "            ahc.fit(embeddings)\n",
        "            labels = ahc.labels_\n",
        "        except:\n",
        "            print('Ошибка:', traceback.format_exc())\n",
        "            continue\n",
        "        ann_hyp = Annotation(uri=uri)\n",
        "        for segment, label in zip(segments, labels):\n",
        "            ann_hyp[segment] = str(label)\n",
        "        uri2ann_hyp[uri] = split_overlap_part(ann_hyp.support())\n",
        "\n",
        "    if return_hyp:\n",
        "        return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap), uri2ann_hyp\n",
        "    return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap)\n",
        "\n",
        "\n",
        "def get_ahc_params(embedder_name, uri2data, uri2ann_ref, skip_overlap=True, metric='der'):\n",
        "\n",
        "  \n",
        "    def ahc_obj(trial):\n",
        "        trial.suggest_float('distance_threshold', 0.5, 1)\n",
        "        trial.suggest_categorical('linkage', ['complete', 'average', 'single'])\n",
        "\n",
        "        report = get_ahc_clustering(embedder_name, uri2data, uri2ann_ref,  trial.params, skip_overlap=skip_overlap, metric=metric)\n",
        "        if metric == 'der':\n",
        "            return report.loc['TOTAL', 'diarization error rate'].values[0]\n",
        "        elif metric == 'jer':\n",
        "            return report.loc['TOTAL', 'jaccard error rate'].values[0]\n",
        "        else:\n",
        "            print(\"unknown metric\")\n",
        "            return\n",
        "\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(ahc_obj, n_trials=15, timeout=1200)\n",
        "    return study.best_params, study.best_value"
      ],
      "metadata": {
        "id": "DXUElmuGWwbp"
      },
      "id": "DXUElmuGWwbp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectrul Clustering"
      ],
      "metadata": {
        "id": "c1KpHrTD1Y1C"
      },
      "id": "c1KpHrTD1Y1C"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spectralcluster"
      ],
      "metadata": {
        "id": "jeIZGR4AXMhF"
      },
      "id": "jeIZGR4AXMhF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spectralcluster.autotune import AutoTune\n",
        "from spectralcluster.constraint import ConstraintName, ConstraintOptions\n",
        "from spectralcluster.laplacian import LaplacianType\n",
        "from spectralcluster.refinement import RefinementName, RefinementOptions, ThresholdType, SymmetrizeType\n",
        "from spectralcluster.spectral_clusterer import SpectralClusterer\n",
        "\n",
        "def get_spectrul_clustering(embedder_name, uri2data, uri2ann_ref, skip_overlap=True, metric='der', return_hyp=False):\n",
        "    uri2ann_hyp = {}\n",
        "    for uri in uri2data:\n",
        "        embeddings_raw, segments = uri2data[uri]\n",
        "        embeddings = transform_embeddings(embeddings_raw, embedder_name)\n",
        "        embeddings[np.isnan(embeddings)] = 1\n",
        "        embeddings[np.isinf(embeddings)] = 100\n",
        "        try:\n",
        "            TURNTODIARIZE_REFINEMENT_SEQUENCE = [\n",
        "                RefinementName.RowWiseThreshold, RefinementName.Symmetrize\n",
        "            ]\n",
        "\n",
        "            turntodiarize_refinement_options = RefinementOptions(\n",
        "                thresholding_soft_multiplier=0.01,\n",
        "                thresholding_type=ThresholdType.Percentile,\n",
        "                thresholding_with_binarization=True,\n",
        "                thresholding_preserve_diagonal=True,\n",
        "                symmetrize_type=SymmetrizeType.Average,\n",
        "                refinement_sequence=TURNTODIARIZE_REFINEMENT_SEQUENCE)\n",
        "\n",
        "            turntodiarize_auto_tune = AutoTune(\n",
        "                p_percentile_min=0.40,\n",
        "                p_percentile_max=0.95,\n",
        "                init_search_step=0.05,\n",
        "                search_level=1)\n",
        "\n",
        "            turntodiarize_clusterer = SpectralClusterer(\n",
        "                min_clusters=2,\n",
        "                max_clusters=30,\n",
        "                refinement_options=turntodiarize_refinement_options,\n",
        "                autotune=turntodiarize_auto_tune,\n",
        "                laplacian_type=LaplacianType.GraphCut,\n",
        "                row_wise_renorm=True,\n",
        "                custom_dist=\"cosine\")\n",
        "\n",
        "            labels = turntodiarize_clusterer.predict(embeddings)\n",
        "        except:\n",
        "            print('Ошибка:', traceback.format_exc())\n",
        "            continue\n",
        "        ann_hyp = Annotation(uri=uri)\n",
        "        for segment, label in zip(segments, labels):\n",
        "            ann_hyp[segment] = str(label)\n",
        "        uri2ann_hyp[uri] = split_overlap_part(ann_hyp.support())\n",
        "\n",
        "    if return_hyp:\n",
        "        return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap), uri2ann_hyp\n",
        "    return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap)"
      ],
      "metadata": {
        "id": "V8aCUpnCXR7w"
      },
      "id": "V8aCUpnCXR7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vbx Clustering"
      ],
      "metadata": {
        "id": "pEn8hoT_1hFA"
      },
      "id": "pEn8hoT_1hFA"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "import traceback\n",
        "def get_vbx_clustering(embedder_name, uri2data, uri2ann_ref, params, skip_overlap=True, metric='der', return_hyp=False):\n",
        "    uri2ann_hyp = {}\n",
        "    for uri in tqdm(uri2data):\n",
        "        embeddings_raw, segments = uri2data[uri]\n",
        "        embeddings = transform_embeddings(embeddings_raw, embedder_name)\n",
        "        embeddings[np.isnan(embeddings)] = 1\n",
        "        embeddings[np.isinf(embeddings)] = 100\n",
        "\n",
        "        plda_mu, plda_tr, plda_psi = prepare_plda(embedder_name)\n",
        "        lda_dim = 128\n",
        "        mean = np.zeros(lda_dim)\n",
        "        invW = np.eye(lda_dim)\n",
        "        V = np.diag(np.sqrt(plda_psi[:lda_dim]))\n",
        "        \n",
        "        features = (embeddings - plda_mu).dot(plda_tr.T)[:, :lda_dim]\n",
        "        try:\n",
        "            np.random.seed(0)\n",
        "            q, sp, L = VB_diarization(\n",
        "                              features, mean, invW, V, \n",
        "                              pi=None, \n",
        "                              gamma=None, \n",
        "                              maxIters=50, \n",
        "                              epsilon=1e-6,\n",
        "                              maxSpeakers=30,\n",
        "                              Fa=0.3,\n",
        "                              **params\n",
        "                          )\n",
        "            labels = np.argmax(q, axis=1)\n",
        "            assert labels.shape == (features.shape[0],)\n",
        "        except:\n",
        "            print('Ошибка:', traceback.format_exc())\n",
        "            continue\n",
        "        ann_hyp = Annotation(uri=uri)\n",
        "        for segment, label in zip(segments, labels):\n",
        "            ann_hyp[segment] = str(label)\n",
        "        uri2ann_hyp[uri] = split_overlap_part(ann_hyp.support())\n",
        "\n",
        "    if return_hyp:\n",
        "        return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap), uri2ann_hyp\n",
        "    return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap)\n",
        "\n",
        "\n",
        "def get_vbx_params(embedder_name, uri2data, uri2ann_ref, skip_overlap=True, metric='der'):\n",
        "\n",
        "    def vbx_obj(trial):\n",
        "        trial.suggest_float('loopProb', 0.9, 0.99)\n",
        "        trial.suggest_float('Fb', 4, 10)\n",
        "\n",
        "        report = get_vbx_clustering(embedder_name, uri2data, uri2ann_ref,  trial.params, skip_overlap=skip_overlap, metric=metric)\n",
        "        if metric == 'der':\n",
        "            return report.loc['TOTAL', 'diarization error rate'].values[0]\n",
        "        elif metric == 'jer':\n",
        "            return report.loc['TOTAL', 'jaccard error rate'].values[0]\n",
        "        else:\n",
        "            print(\"unknown metric\")\n",
        "            return\n",
        "\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(vbx_obj, n_trials=10)\n",
        "    return study.best_params, study.best_value"
      ],
      "metadata": {
        "id": "jmm5bpjS1FIy"
      },
      "id": "jmm5bpjS1FIy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vbx with AHC Initialization"
      ],
      "metadata": {
        "id": "iy4T6-Fh1p2Z"
      },
      "id": "iy4T6-Fh1p2Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import traceback\n",
        "\n",
        "def get_ahc_vbx_clustering(embedder_name, uri2data, uri2ann_ref, ahc_params, vbx_params, skip_overlap=True, metric='der', return_hyp=False):\n",
        "    uri2ann_hyp = {}\n",
        "    it=1\n",
        "    for uri in tqdm(uri2data):\n",
        "        embeddings_raw, segments = uri2data[uri]\n",
        "        embeddings = transform_embeddings(embeddings_raw, embedder_name)\n",
        "\n",
        "        plda_mu, plda_tr, plda_psi = prepare_plda(embedder_name)\n",
        "        \n",
        "        lda_dim = 128\n",
        "        mean = np.zeros(lda_dim)\n",
        "        invW = np.eye(lda_dim)\n",
        "        V = np.diag(np.sqrt(plda_psi[:lda_dim]))\n",
        "\n",
        "        embeddings[np.isnan(embeddings)] = 1\n",
        "        embeddings[np.isinf(embeddings)] = 100\n",
        "        \n",
        "        features = (embeddings - plda_mu).dot(plda_tr.T)[:, :lda_dim]\n",
        "\n",
        "        try:\n",
        "            ahc = AgglomerativeClustering(\n",
        "                          n_clusters=None,\n",
        "                          distance_threshold=ahc_params['distance_threshold'],\n",
        "                          affinity='cosine',\n",
        "                          linkage=ahc_params['linkage']\n",
        "                  )\n",
        "            \n",
        "            ahc.fit(embeddings)\n",
        "            labels = ahc.labels_\n",
        "            \n",
        "            maxSpeakers = len(np.unique(labels))\n",
        "            I = np.eye(maxSpeakers)\n",
        "            q = I[labels]\n",
        "            \n",
        "            np.random.seed(0)\n",
        "            q, sp, L = VB_diarization(\n",
        "                            features, mean, invW, V, \n",
        "                            pi=np.sum(q, axis=0),\n",
        "                            gamma=q, \n",
        "                            maxSpeakers=maxSpeakers, \n",
        "                            maxIters=50,\n",
        "                            epsilon=1e-6,\n",
        "                            loopProb=vbx_params['loopProb'], \n",
        "                            Fa=0.3, \n",
        "                            Fb=vbx_params['Fb']\n",
        "                      )\n",
        "            labels = np.argmax(q, axis=1)\n",
        "            assert labels.shape == (features.shape[0],)\n",
        "        except:\n",
        "            print('Ошибка:', traceback.format_exc())\n",
        "            continue\n",
        "\n",
        "        ann_hyp = Annotation(uri=uri)\n",
        "        for segment, label in zip(segments, labels):\n",
        "            ann_hyp[segment] = str(label)\n",
        "        uri2ann_hyp[uri] = split_overlap_part(ann_hyp.support())\n",
        "\n",
        "    if return_hyp:\n",
        "        return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap), uri2ann_hyp\n",
        "    return get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap)\n",
        "\n",
        "\n",
        "def get_ahc_vbx_params(embedder_name, uri2data, uri2ann_ref, ahc_params, skip_overlap=True, metric='der'):\n",
        "    best_score, best_params = 100, None\n",
        "    for lp in [0.9, 0.92, 0.95, 0.97, 0.99]:\n",
        "        for fb in [1, 4, 6, 7.5, 8, 10]:\n",
        "            vbx_params = {\n",
        "                'loopProb': lp,\n",
        "                'Fb': fb\n",
        "            }\n",
        "            report = get_ahc_vbx_clustering(embedder_name, uri2data, uri2ann_ref, ahc_params, vbx_params, skip_overlap=skip_overlap, metric=metric)\n",
        "            if metric == 'der':\n",
        "                cur_score = report.loc['TOTAL', 'diarization error rate'].values[0]\n",
        "            elif metric == 'jer':\n",
        "                cur_score = report.loc['TOTAL', 'jaccard error rate'].values[0]\n",
        "            else:\n",
        "                print(\"unknown metric\")\n",
        "                return \n",
        "            if cur_score < best_score:\n",
        "                best_score = cur_score\n",
        "                best_params = vbx_params\n",
        "    return best_params, best_score"
      ],
      "metadata": {
        "id": "BXmNeZMk1IT4"
      },
      "id": "BXmNeZMk1IT4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "-Vi3PqgK2E9q"
      },
      "id": "-Vi3PqgK2E9q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agglomerative Clustering"
      ],
      "metadata": {
        "id": "Jt_ubNf5TnJO"
      },
      "id": "Jt_ubNf5TnJO"
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in ['der', 'jer']:\n",
        "    for skip_overlap in [True, False]:\n",
        "        for dataset_name in ['ami', 'voxconverse', 'aishell']:\n",
        "            uri2ann_ref = np.load(\n",
        "                    f'{ROOT}/annotations/{dataset_name}/{dataset_name}_dev_uri2ann_ref.npy', \n",
        "                    allow_pickle=True\n",
        "                ).item()\n",
        "            for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "        \n",
        "                uri2data = np.load(\n",
        "                        f'{ROOT}/embeddings/skip_overlap={str(skip_overlap)}/{dataset_name}/{dataset_name}_dev_uri2data_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "\n",
        "                best_params, best_value = get_ahc_params(embedder_name, uri2data, uri2ann_ref, skip_overlap=skip_overlap, metric=metric)\n",
        "                best_params['value'] = best_value\n",
        "                print(f'{metric}, {skip_overlap}, {dataset_name}, {embedder_name}, best_value={best_value}')\n",
        "                np.save(f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/ahc/{dataset_name}_{embedder_name}.npy', best_params)"
      ],
      "metadata": {
        "id": "sMAr-XY5Vrz9"
      },
      "id": "sMAr-XY5Vrz9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectrul Clustering"
      ],
      "metadata": {
        "id": "aHKTqn1xlVDt"
      },
      "id": "aHKTqn1xlVDt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VBx Clustering"
      ],
      "metadata": {
        "id": "fk9yNMtJVpEi"
      },
      "id": "fk9yNMtJVpEi"
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in ['der', 'jer']:\n",
        "    for skip_overlap in [True, False]:\n",
        "        for dataset_name in ['ami', 'voxconverse', 'aishell']:\n",
        "            uri2ann_ref = np.load(\n",
        "                f'{ROOT}/annotations/{dataset_name}/{dataset_name}_dev_uri2ann_ref.npy', \n",
        "                allow_pickle=True\n",
        "                ).item()\n",
        "            for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "                uri2data = np.load(\n",
        "                    f'{ROOT}/embeddings/skip_overlap={str(skip_overlap)}/{dataset_name}/{dataset_name}_dev_uri2data_{embedder_name}.npy',\n",
        "                    allow_pickle=True\n",
        "                    ).item()\n",
        "\n",
        "                best_params, best_value = get_vbx_params(embedder_name, uri2data, uri2ann_ref, skip_overlap=skip_overlap, metric=metric)\n",
        "                best_params['value'] = best_value\n",
        "                print(f'{skip_overlap}, {dataset_name}, {embedder_name}, best_value={best_value}')\n",
        "                np.save(f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/vbx/{dataset_name}_{embedder_name}.npy', best_params)"
      ],
      "metadata": {
        "id": "Yh8--eeM5_So"
      },
      "id": "Yh8--eeM5_So",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VBx clustering + Agglomerative clustering initialization"
      ],
      "metadata": {
        "id": "zeALFI8pA-f_"
      },
      "id": "zeALFI8pA-f_"
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in ['der', 'jer']:\n",
        "    for skip_overlap in [True, False]:\n",
        "        if metric == 'der' and skip_overlap == True:\n",
        "            continue\n",
        "        for dataset_name in ['ami', 'voxconverse', 'aishell']:\n",
        "            if metric == 'der' and skip_overlap == False and dataset_name == 'ami':\n",
        "                continue\n",
        "            uri2ann_ref = np.load(\n",
        "                    f'{ROOT}/annotations/{dataset_name}/{dataset_name}_dev_uri2ann_ref.npy', \n",
        "                    allow_pickle=True\n",
        "                ).item()\n",
        "            for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "                uri2data = np.load(\n",
        "                        f'{ROOT}/embeddings/skip_overlap={str(skip_overlap)}/{dataset_name}/{dataset_name}_dev_uri2data_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "                ahc_params = np.load(\n",
        "                        f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/ahc/{dataset_name}_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "                best_params, best_value = get_ahc_vbx_params(embedder_name, uri2data, uri2ann_ref, ahc_params, skip_overlap=skip_overlap, metric=metric)\n",
        "                best_params['value'] = best_value\n",
        "                print(f'{metric}, {skip_overlap}, {dataset_name}, {embedder_name}, best_value={best_value}')\n",
        "                np.save(f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/ahc_vbx/{dataset_name}_{embedder_name}.npy', best_params)\n"
      ],
      "metadata": {
        "id": "W4W21xpcLBkW"
      },
      "id": "W4W21xpcLBkW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvImfVUY_pGM"
      },
      "source": [
        "## Test Clustering"
      ],
      "id": "lvImfVUY_pGM"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_value(metric, report):\n",
        "    if metric == 'der':\n",
        "        return report.loc['TOTAL', 'diarization error rate'].values[0]\n",
        "    elif metric == 'jer':\n",
        "        return report.loc['TOTAL', 'jaccard error rate'].values[0]"
      ],
      "metadata": {
        "id": "nZ4humpkz9-M"
      },
      "id": "nZ4humpkz9-M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6_6oxp8_pGM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "it = 1\n",
        "for metric in ['der']: # ['der', 'jer']:\n",
        "    for skip_overlap in [True, False]:\n",
        "        for dataset_name in ['ami', 'voxconverse', 'aishell']:\n",
        "            uri2ann_ref = np.load(\n",
        "                    f'{ROOT}/annotations/{dataset_name}/{dataset_name}_test_uri2ann_ref.npy', \n",
        "                    allow_pickle=True\n",
        "                ).item()\n",
        "            for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "                print(f'{it}: {metric}, {skip_overlap}, {dataset_name}, {embedder_name}')\n",
        "                it += 1\n",
        "                uri2data = np.load(\n",
        "                        f'{ROOT}/embeddings/skip_overlap={str(skip_overlap)}/{dataset_name}/{dataset_name}_test_uri2data_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "\n",
        "\n",
        "                # ahc clustering\n",
        "                ahc_params = np.load(\n",
        "                        f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/ahc/{dataset_name}_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "                ahc_params.pop('value')\n",
        "                report, uri2ann_hyp = get_ahc_clustering(embedder_name, uri2data, uri2ann_ref, ahc_params, skip_overlap=skip_overlap, metric=metric, return_hyp=True)\n",
        "                print(\"AHC:\", get_value(metric, report))\n",
        "                np.save(f'{ROOT}/ann_hyp/{metric}/skip_overlap={str(skip_overlap)}/ahc/{dataset_name}_{embedder_name}.npy', uri2ann_hyp)\n",
        "\n",
        "\n",
        "                # spectrul clustering\n",
        "                report, uri2ann_hyp = get_spectrul_clustering(embedder_name, uri2data, uri2ann_ref, skip_overlap=skip_overlap, metric=metric, return_hyp=True)\n",
        "                print(\"SpectrulClustering:\", get_value(metric, report), end=\", \")\n",
        "                np.save(f'{ROOT}/ann_hyp/{metric}/skip_overlap={str(skip_overlap)}/spectrul/{dataset_name}_{embedder_name}.npy', uri2ann_hyp)\n",
        "\n",
        "\n",
        "                # vbx clustering\n",
        "                vbx_params = np.load(\n",
        "                        f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/vbx/{dataset_name}_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "                vbx_params.pop('value')\n",
        "                report, uri2ann_hyp = get_vbx_clustering(embedder_name, uri2data, uri2ann_ref, vbx_params, skip_overlap=skip_overlap, metric=metric, return_hyp=True)\n",
        "                print(\"Vbx:\", get_value(metric, report), end=\", \")\n",
        "                np.save(f'{ROOT}/ann_hyp/{metric}/skip_overlap={str(skip_overlap)}/vbx/{dataset_name}_{embedder_name}.npy', uri2ann_hyp)\n",
        "\n",
        "\n",
        "                # ahc_vbx clustering\n",
        "                ahc_vbx_params = np.load(\n",
        "                        f'{ROOT}/best_params/{metric}/skip_overlap={str(skip_overlap)}/ahc_vbx/{dataset_name}_{embedder_name}.npy',\n",
        "                        allow_pickle=True\n",
        "                    ).item()\n",
        "                ahc_vbx_params.pop('value')\n",
        "                report, uri2ann_hyp = get_ahc_vbx_clustering(embedder_name, uri2data, uri2ann_ref, ahc_params, ahc_vbx_params, skip_overlap=skip_overlap, metric=metric, return_hyp=True)\n",
        "                print(\"AHC_Vbx:\", get_value(metric, report))\n",
        "                np.save(f'{ROOT}/ann_hyp/{metric}/skip_overlap={str(skip_overlap)}/ahc_vbx/{dataset_name}_{embedder_name}.npy', uri2ann_hyp)"
      ],
      "id": "a6_6oxp8_pGM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pzSdaqs_pGM"
      },
      "source": [
        "# Performance metrics"
      ],
      "id": "0pzSdaqs_pGM"
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = ['ami_brno', 'ami_clova', 'ami_speechbrain', 'aishell_brno', 'aishell_clova', 'aishell_speechbrain', 'voxconverse_brno', 'voxconverse_clova', 'voxconverse_speechbrain']\n",
        "\n",
        "def get_results(metric, skip_overlap):\n",
        "    d = {\n",
        "        'ahc': [],\n",
        "        'vbx': [],\n",
        "        'ahc_vbx': [],\n",
        "        'spectrul': []\n",
        "    }\n",
        "    for dataset_name in ['ami', 'aishell', 'voxconverse']:\n",
        "        uri2ann_ref = np.load(\n",
        "                              f'{ROOT}/annotations/{dataset_name}/{dataset_name}_test_uri2ann_ref.npy', \n",
        "                              allow_pickle=True\n",
        "                          ).item()\n",
        "        for embedder_name in ['brno', 'clova', 'speechbrain']:\n",
        "            for clst in ['ahc', 'spectrul', 'vbx', 'ahc_vbx']:\n",
        "                uri2ann_hyp = np.load(\n",
        "                                  f'{ROOT}/ann_hyp/{metric}/skip_overlap={str(skip_overlap)}/{clst}/{dataset_name}_{embedder_name}.npy',\n",
        "                                  allow_pickle=True\n",
        "                              ).item()\n",
        "\n",
        "                report = get_clst_metric_res(metric, uri2ann_ref, uri2ann_hyp, skip_overlap=skip_overlap)\n",
        "                d[clst].append(get_value(metric, report))\n",
        "    return d"
      ],
      "metadata": {
        "id": "gmnBmbuAaIlh"
      },
      "id": "gmnBmbuAaIlh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4yl_wvy_pGM"
      },
      "source": [
        "### Diarization Error Rate (DER)"
      ],
      "id": "j4yl_wvy_pGM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1IIMq6x_pGN",
        "outputId": "9403734a-a6a5-4d5d-86ef-dc2e7b666aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               ahc        vbx    ahc_vbx   spectrul\n",
              "ami_brno                  5.737887   6.265993   3.235103   3.569658\n",
              "ami_clova                 5.051559   7.725323   3.703079   3.526255\n",
              "ami_speechbrain           6.550472   5.514422   2.933022   3.376954\n",
              "aishell_brno             22.434028   8.029049  21.730432   9.375953\n",
              "aishell_clova            10.374267   9.244718   6.931529  13.335255\n",
              "aishell_speechbrain      22.966473   6.588633  22.350630  10.622688\n",
              "voxconverse_brno          4.655823  11.948572   3.411799  14.594538\n",
              "voxconverse_clova         7.222782  15.360753   6.510049  14.390040\n",
              "voxconverse_speechbrain   4.874131  11.671924   3.529485  13.848180"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62832034-de14-484f-90a8-3d4604ccae01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ahc</th>\n",
              "      <th>vbx</th>\n",
              "      <th>ahc_vbx</th>\n",
              "      <th>spectrul</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ami_brno</th>\n",
              "      <td>5.737887</td>\n",
              "      <td>6.265993</td>\n",
              "      <td>3.235103</td>\n",
              "      <td>3.569658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_clova</th>\n",
              "      <td>5.051559</td>\n",
              "      <td>7.725323</td>\n",
              "      <td>3.703079</td>\n",
              "      <td>3.526255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_speechbrain</th>\n",
              "      <td>6.550472</td>\n",
              "      <td>5.514422</td>\n",
              "      <td>2.933022</td>\n",
              "      <td>3.376954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_brno</th>\n",
              "      <td>22.434028</td>\n",
              "      <td>8.029049</td>\n",
              "      <td>21.730432</td>\n",
              "      <td>9.375953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_clova</th>\n",
              "      <td>10.374267</td>\n",
              "      <td>9.244718</td>\n",
              "      <td>6.931529</td>\n",
              "      <td>13.335255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_speechbrain</th>\n",
              "      <td>22.966473</td>\n",
              "      <td>6.588633</td>\n",
              "      <td>22.350630</td>\n",
              "      <td>10.622688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_brno</th>\n",
              "      <td>4.655823</td>\n",
              "      <td>11.948572</td>\n",
              "      <td>3.411799</td>\n",
              "      <td>14.594538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_clova</th>\n",
              "      <td>7.222782</td>\n",
              "      <td>15.360753</td>\n",
              "      <td>6.510049</td>\n",
              "      <td>14.390040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_speechbrain</th>\n",
              "      <td>4.874131</td>\n",
              "      <td>11.671924</td>\n",
              "      <td>3.529485</td>\n",
              "      <td>13.848180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62832034-de14-484f-90a8-3d4604ccae01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62832034-de14-484f-90a8-3d4604ccae01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62832034-de14-484f-90a8-3d4604ccae01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "d = get_results('der', True)\n",
        "np.save(f'{ROOT}/der_True.npy', d)\n",
        "df = pd.DataFrame(d, index=indexes)\n",
        "df"
      ],
      "id": "O1IIMq6x_pGN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d = get_results('der', False)\n",
        "np.save(f'{ROOT}/der_False.npy', d)\n",
        "df = pd.DataFrame(d, index=indexes)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "W4jrPLirdmg3",
        "outputId": "e4fd579c-6651-428a-a908-8dd7a45fc2e8"
      },
      "id": "W4jrPLirdmg3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               ahc        vbx    ahc_vbx   spectrul\n",
              "ami_brno                 19.981081  21.599858  17.912833  17.737017\n",
              "ami_clova                22.782156  22.099241  19.286966  17.807702\n",
              "ami_speechbrain          21.469331  19.646412  17.248639  17.627360\n",
              "aishell_brno             13.194266  12.880940   9.869140  13.880085\n",
              "aishell_clova            16.963574  14.230856  14.741873  17.622040\n",
              "aishell_speechbrain      16.853835  11.345442  11.536344  15.141068\n",
              "voxconverse_brno          8.719711  15.836690   6.286200  17.022805\n",
              "voxconverse_clova         9.100599  19.466095   7.222013  16.866941\n",
              "voxconverse_speechbrain   8.377691  15.478372   7.144937  16.350528"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6488eba6-1147-4b43-a40a-c6221bd09ecb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ahc</th>\n",
              "      <th>vbx</th>\n",
              "      <th>ahc_vbx</th>\n",
              "      <th>spectrul</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ami_brno</th>\n",
              "      <td>19.981081</td>\n",
              "      <td>21.599858</td>\n",
              "      <td>17.912833</td>\n",
              "      <td>17.737017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_clova</th>\n",
              "      <td>22.782156</td>\n",
              "      <td>22.099241</td>\n",
              "      <td>19.286966</td>\n",
              "      <td>17.807702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_speechbrain</th>\n",
              "      <td>21.469331</td>\n",
              "      <td>19.646412</td>\n",
              "      <td>17.248639</td>\n",
              "      <td>17.627360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_brno</th>\n",
              "      <td>13.194266</td>\n",
              "      <td>12.880940</td>\n",
              "      <td>9.869140</td>\n",
              "      <td>13.880085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_clova</th>\n",
              "      <td>16.963574</td>\n",
              "      <td>14.230856</td>\n",
              "      <td>14.741873</td>\n",
              "      <td>17.622040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_speechbrain</th>\n",
              "      <td>16.853835</td>\n",
              "      <td>11.345442</td>\n",
              "      <td>11.536344</td>\n",
              "      <td>15.141068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_brno</th>\n",
              "      <td>8.719711</td>\n",
              "      <td>15.836690</td>\n",
              "      <td>6.286200</td>\n",
              "      <td>17.022805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_clova</th>\n",
              "      <td>9.100599</td>\n",
              "      <td>19.466095</td>\n",
              "      <td>7.222013</td>\n",
              "      <td>16.866941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_speechbrain</th>\n",
              "      <td>8.377691</td>\n",
              "      <td>15.478372</td>\n",
              "      <td>7.144937</td>\n",
              "      <td>16.350528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6488eba6-1147-4b43-a40a-c6221bd09ecb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6488eba6-1147-4b43-a40a-c6221bd09ecb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6488eba6-1147-4b43-a40a-c6221bd09ecb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHUGgL_P_pGN"
      },
      "source": [
        "### Jaccard Error Rate (JER)"
      ],
      "id": "yHUGgL_P_pGN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d = get_results('jer', True)\n",
        "np.save(f'{ROOT}/jer_True.npy', d)\n",
        "df = pd.DataFrame(d, index=indexes)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Hfsm_GFSeTKC",
        "outputId": "02fe15a9-6db4-48d7-c80e-7a8024ae246f"
      },
      "id": "Hfsm_GFSeTKC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               ahc        vbx    ahc_vbx   spectrul\n",
              "ami_brno                 11.157421  17.253626   9.866726  13.352156\n",
              "ami_clova                13.061978  19.895100  11.032688  13.053777\n",
              "ami_speechbrain          10.327392  18.692219   8.496096  12.974931\n",
              "aishell_brno             16.251517  21.767584  14.218811  34.581305\n",
              "aishell_clova            18.371380  31.400866  15.090445  39.720742\n",
              "aishell_speechbrain      16.028252  24.228364  12.092401  35.440133\n",
              "voxconverse_brno         17.767039  60.581274  15.860347  57.402045\n",
              "voxconverse_clova        24.282323  66.064301  23.545159  57.417113\n",
              "voxconverse_speechbrain  14.805727  57.740555  14.814383  56.462588"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d18ca40-596a-4440-bab6-9dc18ab923b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ahc</th>\n",
              "      <th>vbx</th>\n",
              "      <th>ahc_vbx</th>\n",
              "      <th>spectrul</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ami_brno</th>\n",
              "      <td>11.157421</td>\n",
              "      <td>17.253626</td>\n",
              "      <td>9.866726</td>\n",
              "      <td>13.352156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_clova</th>\n",
              "      <td>13.061978</td>\n",
              "      <td>19.895100</td>\n",
              "      <td>11.032688</td>\n",
              "      <td>13.053777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_speechbrain</th>\n",
              "      <td>10.327392</td>\n",
              "      <td>18.692219</td>\n",
              "      <td>8.496096</td>\n",
              "      <td>12.974931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_brno</th>\n",
              "      <td>16.251517</td>\n",
              "      <td>21.767584</td>\n",
              "      <td>14.218811</td>\n",
              "      <td>34.581305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_clova</th>\n",
              "      <td>18.371380</td>\n",
              "      <td>31.400866</td>\n",
              "      <td>15.090445</td>\n",
              "      <td>39.720742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_speechbrain</th>\n",
              "      <td>16.028252</td>\n",
              "      <td>24.228364</td>\n",
              "      <td>12.092401</td>\n",
              "      <td>35.440133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_brno</th>\n",
              "      <td>17.767039</td>\n",
              "      <td>60.581274</td>\n",
              "      <td>15.860347</td>\n",
              "      <td>57.402045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_clova</th>\n",
              "      <td>24.282323</td>\n",
              "      <td>66.064301</td>\n",
              "      <td>23.545159</td>\n",
              "      <td>57.417113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_speechbrain</th>\n",
              "      <td>14.805727</td>\n",
              "      <td>57.740555</td>\n",
              "      <td>14.814383</td>\n",
              "      <td>56.462588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d18ca40-596a-4440-bab6-9dc18ab923b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d18ca40-596a-4440-bab6-9dc18ab923b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d18ca40-596a-4440-bab6-9dc18ab923b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC4Ev7JG_pGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "03bc6951-6fee-4e84-b6b5-26f23d2d36c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               ahc        vbx    ahc_vbx   spectrul\n",
              "ami_brno                 23.849321  30.040257  22.918917  24.847648\n",
              "ami_clova                27.590221  35.263031  25.383640  24.783689\n",
              "ami_speechbrain          26.458441  29.921606  22.270399  24.755405\n",
              "aishell_brno             18.922774  26.640720  15.962324  37.450323\n",
              "aishell_clova            20.113635  45.441097  14.677727  42.081272\n",
              "aishell_speechbrain      21.954604  23.170361  18.623527  38.354064\n",
              "voxconverse_brno         18.491692  59.155198  18.900910  59.101058\n",
              "voxconverse_clova        23.148184  68.111908  27.563112  59.196431\n",
              "voxconverse_speechbrain  17.954066  56.906990  17.793737  58.262182"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39ae8532-fe25-4c41-85ab-9c65b8fca78a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ahc</th>\n",
              "      <th>vbx</th>\n",
              "      <th>ahc_vbx</th>\n",
              "      <th>spectrul</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ami_brno</th>\n",
              "      <td>23.849321</td>\n",
              "      <td>30.040257</td>\n",
              "      <td>22.918917</td>\n",
              "      <td>24.847648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_clova</th>\n",
              "      <td>27.590221</td>\n",
              "      <td>35.263031</td>\n",
              "      <td>25.383640</td>\n",
              "      <td>24.783689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ami_speechbrain</th>\n",
              "      <td>26.458441</td>\n",
              "      <td>29.921606</td>\n",
              "      <td>22.270399</td>\n",
              "      <td>24.755405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_brno</th>\n",
              "      <td>18.922774</td>\n",
              "      <td>26.640720</td>\n",
              "      <td>15.962324</td>\n",
              "      <td>37.450323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_clova</th>\n",
              "      <td>20.113635</td>\n",
              "      <td>45.441097</td>\n",
              "      <td>14.677727</td>\n",
              "      <td>42.081272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aishell_speechbrain</th>\n",
              "      <td>21.954604</td>\n",
              "      <td>23.170361</td>\n",
              "      <td>18.623527</td>\n",
              "      <td>38.354064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_brno</th>\n",
              "      <td>18.491692</td>\n",
              "      <td>59.155198</td>\n",
              "      <td>18.900910</td>\n",
              "      <td>59.101058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_clova</th>\n",
              "      <td>23.148184</td>\n",
              "      <td>68.111908</td>\n",
              "      <td>27.563112</td>\n",
              "      <td>59.196431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voxconverse_speechbrain</th>\n",
              "      <td>17.954066</td>\n",
              "      <td>56.906990</td>\n",
              "      <td>17.793737</td>\n",
              "      <td>58.262182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39ae8532-fe25-4c41-85ab-9c65b8fca78a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39ae8532-fe25-4c41-85ab-9c65b8fca78a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39ae8532-fe25-4c41-85ab-9c65b8fca78a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "d = get_results('jer', False)\n",
        "np.save(f'{ROOT}/jer_False.npy', d)\n",
        "df = pd.DataFrame(d, index=indexes)\n",
        "df"
      ],
      "id": "bC4Ev7JG_pGO"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ep5rwmWIfMhG"
      },
      "id": "ep5rwmWIfMhG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "diarization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AkAFo1_NOVfl",
        "01Uq4cLXEJ0t",
        "cyB8YMlbuN7X",
        "aCX5zZkY0Hwa",
        "CQnd3hPy0OIL",
        "KAAg0bap0Tb9",
        "yM9oGuF8_pGI",
        "8thWKqqwW_3P",
        "FBN5GODvz38L",
        "StnL8_a7z8P9",
        "h7p077C30bST",
        "SK96kRTn0nST",
        "T7RZW3wbcqLt",
        "4YmhbT7i1RC7",
        "c1KpHrTD1Y1C",
        "pEn8hoT_1hFA",
        "iy4T6-Fh1p2Z",
        "-Vi3PqgK2E9q",
        "Jt_ubNf5TnJO",
        "aHKTqn1xlVDt",
        "fk9yNMtJVpEi",
        "zeALFI8pA-f_",
        "lvImfVUY_pGM"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}